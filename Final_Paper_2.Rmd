---
title: "Race, Experiences, and Criminal Sentencing"
author: "Julie Norman, Abraham Alhomadi, and Keaton Manwaring"
date: "12/6/2020"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}

# theme_minimal()
# Libraries
library(tidyverse)
library(lmtest)
library(wooldridge)
library(gridExtra)
library(stargazer)
library(corrgram)
library(broom)
library(car)

```

```{r include=FALSE}
#data cleaning 
df <- filter(crime1, avgsen > 0)

df$race <- with(df, ifelse(df$black == 1, "black", 
                           ifelse(df$hispan == 1, "hisp", "non")))

df$fnfarr86 <- as.factor(df$nfarr86)
df$fnarr86 <- as.factor(df$narr86)

df$narr86sq <- (df$narr86)^2

```


In this paper, we will undertake an econometric examination using the Crime1 dataset in the Wooldrige Package. The dataset contain a total of 2725 observations on 16 distinct variables.It was collected in 1986, in the State of California. Looking at the data, we will aspire to answer the following research question that is the focus of this paper: "How does an individual's income affect average sentencing outcome when they commit a crime? This question has been the subject of policy research for decades and, using the Crime1 dataset, we would like to contribute to the conversation on this issue of economics and criminal justice reform. Our belief as citizens is that we have a collective responsibility to promote better policies and the well-being of our nation through the efficient and just allocation of resources and ensuring that our criminal justice system is in fact "just" in its treatment of citizens who are convicted of a crime. In addition to our focus research question, we will investigate other equally critical questions, some of which include,"Does a person's employment status increase or decrease average sentencing?", " Do blacks get different average sentence lengths than nonblacks?",  and "how does an individual's prior criminal history, if any, contribute to their average sentencing length?". 

Now, to carry out our investigation, we will begin by focusing our annalysis on the the `r nrow(filter(df, avgsen > 0))` individuals in our dataset who have been sentenced. We're filtering out the individuals who have not served prison time as our question is focused on what factors impact sentence length, not whether they've been found guilty at all. We'll regress our dependent variable "avgsen", which is the average sentence length of a convicted criminal, on variant explanatory variables: inc86 (legal income), nfarr86 (felony arrests), pcnv (proportion of prior convictions), durat (recent unemp duration), narr86(times arrested), Black, and Hispanic. Since our data treats black and hispanic as mutually exclusive, we're going to combine our race variable into a single dummy that illustrates whether an individual is black, hispanic, or neither. Our multiregression model would start with the following model and build on from there to test for interaction between variables and to reflect for possible increase or decrease in sentencing length in the short- and long-term. This is our original regression model:

$$ Avgsen= \beta_{0} + \beta_{1}inc86 + \beta_{2}nfarr86 + \beta_{3}narr86 + \beta_{4}pcnv + \beta_{5}durat + \delta_{1}race + u $$


The additional questions will help put our focus question in perspective, and allow us to identify alternative explanations besides an individual's income to why average sentencing length would differ from one person to another, given variables like employment status, criminal history, and race. 


Lastly, for so long, policy makers have been trying to answer the above questions in order to improve economic and criminal justice policy making. They endeavor to identify our criminal justice system flaws and seek to address them, including issues like sentencing discrimination on the basis of income and race, and to improve the efficient and fair allocation of economic resources to all their citizens. This is an interesting economic inquiry, for it touches the heart of one of the challenges that has engulfed our nation. A stable and functioning economic system and a fair criminal justice system are important to maintaining a healthy life style, public safety to guard against social division because of discriminatory economic and criminal justice motives, and to promote a flourishing, economically strong country in the 21st century. For this reason, we are seeking to investigate whether average sentencing in, say, California or other states for that matter, are rendered based on effective, just, and fair laws, or are there discriminatory motives that impact our justice system rendering of sentencing. If discrimination does exist, then as citizens, we have a solemn obligation to put forth facts backed up by objective data and partake in making our country, as our founding fathers envisioned, a "more perfect union." 

Our Crime1 dataset is included in the wooldridge package. We did not collect the data on our own nor do we know precisely how the data was collected. However, we know that the data it contains was collected in the State of California and the arrests data are for the year 1986. The observations reflect men who were born in 1960 or 1961, and the subject men in the dataset all had criminal history and a minimum of one arrest before 1986. So, our regression model, as written above, will provide a multidimensional analysis to explain whether our independent variables listed do or do not have a causal relationship with our dependent variable, Avgsen. We wanted to include gender as a dummy variable in our regression model, but the dataset only contains data on men. Therefore, instead of looking at the relationship between gender and average sentencing, we will dwell on race and average sentencing. 

## Data Exploration

In order to better understand our data we'll look at each variable to check for any violations of the first Gauss Markov assumption: linear parameters. While there's logical expanations for relationships between our explanatory variable and our response variables, we also need to ensure that our data bares out that relationship.

### Average Sentence Length

```{r echo=FALSE}
ggplot(df, aes(x = avgsen))+ 
  xlab("Length in Months") + ylab("Count") + 
  ggtitle("Average Sentence Length Histogram") +
  geom_histogram(binwidth = 5) + 
  theme_minimal()
```

The histogram shows that that the distribution of sentence length is rightly skewed indicating that this model is proabably going to have issues with heteroskedasticity and that a log might be an appropriate adjustment for our model. However, since there are zero values in the variable a log transformation isn't appropriate. It also has a range of 58.9 which shows that this paramater has enough varition that we can use it in the model.  


### Income from 1986

```{r echo=FALSE}
ggplot(df, aes(x = inc86))+ 
  xlab("Income") + ylab("Count") + 
  ggtitle("Histogram of 1986 Legal Income") +
  geom_histogram(binwidth = 20) + 
  theme_minimal()
```

The histogram shows a strong right hand skew indicating that in order to meet the linear parameters assumption, we will need to take the log of the variable. However, since there are so many 0 values we won't be transforming the data Next we need to visualize the relationship between the income and average sentence length. 

```{r echo=FALSE}
ggplot(df, aes(x = inc86, y = (avgsen))) + 
  xlab("Income") + ylab("Average Sentence Length") + 
  ggtitle("1986 Legal Income and Average Sentence Length") +
  geom_smooth(method = 'lm') +
  geom_point() + 
  theme_minimal()
```

The model indicates a week negative association between the income variable and the sentence variable. Due to this, we shouldn't expect a strong impact of this variable in our model. 

### Felony arresting 

```{r echo=FALSE}
ggplot(df, aes(x = nfarr86)) + 
  xlab("1986 Felony Arrests") + ylab("Count") + 
  ggtitle("Historgram of 1986 Felony Arrests") +
  geom_histogram(binwidth = 1) + 
  theme_minimal()
```

The histogram indicates a strong right hand skew in felony arrests. However, the ordinal nature of the data makes it unideal for a multiple regression model. 


```{r echo=FALSE}
ggplot(df, aes(x = fnfarr86, y = avgsen)) + 
  xlab("1986 Felony Arrests") + ylab("Average Sentence in Months") + 
  ggtitle("1986 Legal Income and Average Sentence Length") +
  geom_boxplot() + 
  theme_minimal()


```

The side by side boxplots illustrates that amoung the average sentence length for each number of felony arrests has essentially no association on average. Due to this and the ordinal nature of the variable we should consider removing this variable from our model.  

### Number of Arrests in 1986

```{r echo=FALSE}
ggplot(df, aes(x = narr86)) + 
  xlab("Arrests") + ylab("Count") + 
  ggtitle("Historgram of 1986 Arrests") +
  geom_histogram(binwidth = 1) + 
  theme_minimal()
```

The histogram indicates a strong right hand skew in arrests. However, the ordinal nature of the data makes it again unideal for a multiple regression model. 


```{r echo=FALSE}
ggplot(df, aes(x = fnarr86, y = avgsen)) + 
  xlab("Arrests in 1986") + ylab("Average Sentence in Months") + 
  ggtitle("1986 Legal Income and Average Sentence Length") +
  geom_boxplot() + 
  theme_minimal()

```

Again, he side by side boxplots indicates that amoung the average sentence length for each number of arrests there is essentially no association. While the average sentence for those with 4 felony arrests is higher than the rest, this is merely one data point and as it does not imply an overall trend in the data it's unlikely to be influencial in our model. Due to this and the ordinal nature of the variable we should consider removing this variable from our model.

### Proportion of prior convictions 

```{r echo=FALSE}
ggplot(df, aes(x = pcnv)) + 
  xlab("Proportion of Prior Convictions") + ylab("Count") + 
  ggtitle("Prop of Prior Convictions") +
  geom_histogram(binwidth = .07) + 
  theme_minimal()
```

The histogram indicates that the distribution of th proportion of prior convictions is approximately normal, indicating that this variable is a good candidate for use in a multiple regression model. 

```{r echo=FALSE}
ggplot(df, aes(x = pcnv, y = avgsen)) + 
  xlab("Proportion of Prior Convictions and Average Sentence Length") + ylab("Sentence Length in Months") + 
  ggtitle("Prop of Prior Convictions") +
  geom_smooth(method = 'lm') +
  geom_point() + 
  theme_minimal()

```

This scatterplot indicates a negative association between prior convictions and sentence length. This indicates that as convictions become more common for an individual, their sentence length decreases. This trend is particularly interesting as it does fit a typically assumption of repeat offenders having harsher punishments. While we can only speculate as to the exact nature of this relationship, its possible that other variables such as the types of crimes committed and/or race have a larger impact on average sentence then we wouldn've prevously thought. That makes this variable an ideal candidate for a multiple regression since we can see how this variable combined with other indicators appropriate predict average sentence length.

### Duration of Unemployment

```{r echo=FALSE}
ggplot(df, aes(x = (durat))) + 
  xlab("Duration in Months") + ylab("Count") + 
  ggtitle("Histogram of Unemployment Duration") +
  geom_histogram(binwidth = 5) + 
  theme_minimal()
```

The histogram indicates a strong left hand skew in unemployment duration. This indicates that a logarithmic model might be more appropriate for this variable, however since we have zero values in our data a log isn't appropriate. The measurement unit for duration of unemployment is not given in our data set but since all the other time variables are measured in months we're assuming that here as well. 

```{r echo=FALSE}
ggplot(df, aes(x = (durat), y = (avgsen))) + 
  xlab("Unemployment Duration in Months") + ylab("Average Sentence in Months") + 
  ggtitle("Unemployment and Sentence Length Scatterplot") +
  geom_smooth(method = 'lm') +
  geom_point() + 
  theme_minimal()
```

This scatterplot illustrates a weak positive association between unemployment length and average sentence length. Due too the weakness of the association 

### Race Comparisons


```{r echo=FALSE}
ggplot(df, aes(x = race, y = avgsen)) + 
  xlab("Race") + ylab("Average Sentence in Months") + 
  ggtitle("1986 Legal Income and Average Sentence Length") +
  geom_boxplot() + 
  theme_minimal()

```

The boxplots of average sentence length show minmimal variation accross different racial categories. This indicates that even if there is a statistical significance between the regressions, it is likely of little practical significance. However, since race is a major point in our research question we'll keep this variable in our regression.  

## Model Specification 

Since we're considering eliminating two of the variables, it's important we include them in our models until we've determined the best form for the other variables in our model. 

During our exploration of the variables, we found that due to skewness, a few of our variables could benefit from logs. However, since there are zero values in all of our variables this isn't an option. In order to be safe we'll compare a variatey of quadratic functions on the variables that weren't as skewed to see if it improves our model. 

```{r echo=FALSE}

reg1 <- lm(avgsen ~ (inc86) + narr86 + nfarr86 + pcnv + durat + race, df)
reg2A <- lm((avgsen) ~ inc86 + I(inc86^2) + narr86 + nfarr86 + pcnv + durat + race, df)
reg2B <- lm(avgsen ~ (inc86) + narr86 + I(narr86^2) + nfarr86 + pcnv + durat + race, df)
reg2C <- lm(avgsen ~ (inc86) + narr86 + nfarr86 + I(nfarr86^2) + pcnv + durat + race, df)
reg2D <-  lm((avgsen) ~ inc86 + narr86 + nfarr86 + pcnv + I(pcnv^2) + durat + race, df)
reg2E <- lm(avgsen  ~ inc86 + narr86 + nfarr86 + pcnv + durat + I(durat^2) + race, df)

stargazer(reg1, reg2A, reg2B, reg2C, reg2D, reg2E,  type = "text")
```

Since the regressions 2, 3 and 5 all saw an increase in $\bar R^2$ and then we'll compare those and a mulitple combinations to the original next. 

```{r}

reg3A <- lm((avgsen) ~ inc86 + I(inc86^2) + narr86 + I(narr86^2) + nfarr86 + pcnv + durat + race, df)
reg3B <- lm((avgsen) ~ inc86 + I(inc86^2) + narr86 + nfarr86 + pcnv + I(pcnv^2) + durat + race, df)
reg3C <- lm(avgsen ~ (inc86) + narr86 + narr86sq + nfarr86 + pcnv + pcnvsq + durat + race, df)
reg3D <- lm(avgsen ~ (inc86) + I(inc86^2) + narr86 + I(narr86^2) + nfarr86 + I(nfarr86^2) + pcnv + durat + race, df)

stargazer(reg1, reg3A, reg3B, reg3C, reg3D, type = "text")
```
Since the $\bar R^2$ is highest in regression 4 we'll use that model and double check the form later. For now we can consider the following regression our current model

$$ \widehat{log(Avgsen)} = 22.138 - 0.017(inc) - 2.48(narr86) + 1.22(narr86^2) - 2.495(nfarr86) - 27.502(pcnv) +  20.051(pcnv^2) + 0.206(durat) - 1.423(racehisp) - 3.141(racenon) $$


## Model Assumptions 
                                      
We used an Ordinary Least Square (OLS) estimating method to compute the coefficients of our parameters. Our model complies with all five of OLS multiple regression assumptions. First, our regression model is linear in parameters, as illustrated by our model above. Additionally, the sampling of the observations was undertaken randomly so we've met that condition as well. The third condition is that there's no multicollinearity. Since the independent variables is `r var(df$avgsen)` which is greater than zero and we have no variable repetition so we just need to check that we have no variables that are perfect multiples of each other 

```{r echo=FALSE}
inc86_lm <- lm((inc86) ~ narr86 + I(narr86^2) + nfarr86 + pcnv + I(pcnv^2) + durat + race, df)
nfarr86_lm <- lm(nfarr86 ~ inc86 + narr86 + I(narr86^2) + pcnv + I(pcnv^2) + durat + race, df)
narr86_lm <- lm(narr86 ~ inc86 + I(narr86^2) + nfarr86 + pcnv + I(pcnv^2) + durat + race, df)
pcnv_lm <- lm(pcnv ~ inc86 + narr86 + I(narr86^2) + nfarr86  + I(pcnv^2) + durat + race, df)
durat_lm <- lm(durat ~ inc86 + narr86 + I(narr86^2) + nfarr86 + pcnv + I(pcnv^2) + race, df)
black_lm <- lm(black ~ inc86 + narr86 + I(narr86^2) + nfarr86 + pcnv + I(pcnv^2) + durat + hispan, df)
hispan_lm <- lm(hispan ~ inc86 + narr86 + I(narr86^2) + nfarr86 + pcnv + I(pcnv^2) + durat + black, df)

vif_list <- list(vif(inc86_lm), vif(nfarr86_lm), vif(narr86_lm), vif(pcnv_lm), vif(durat_lm), vif(black_lm), vif(hispan_lm) )
names(vif_list) <- c("Regress on inc86", "Regress on nfarr86", "Regress on narr86", "Regress on pcnv", "Regress on durat", "Regress on Black", "Regress on Hispanic")
vif_list
```
For our vif output, values between 1 and 5 are considered moderately correlated while values greater than 5 near perfect collinearity. From the output we can see there's strong correlation between inc86 and narr86, because of this we need to remove one of the variables entirely from the regression. Since we're focused oon jail time and non felony arrests can lead to prison time so we're going to eliminate nfarr86 and keep narr86 and its square. 

Otherwise the highest variance inflation factor of all the parameter regressions is 3.555754 while most are between one and two.  Since our strongest correlation is a moderate correlation we've shown there's no multicollinearity and we've met this assumption. The next assumption is the zero conditional mean assumption ie $E(u | inc, narr86, nfarr86, pcnv, durat, race) = 0$. We've already added logs to the model where appropriate and since the visualizations of our variables don't indicate a need for quadratics in our model, we can double check our model specificatioon by looking at the model residuals. 


```{r echo=FALSE}
reg4 <- lm(avgsen ~ (inc86) + narr86 + narr86sq + pcnv + pcnvsq + durat + race, df)

reg4_df <- augment(reg4)
ggplot(reg4_df, aes(x = .fitted, y = .resid)) + 
  ggtitle("Residuals Plot for Regression") +
  xlab("Fitted Values") + ylab("Residuals") + 
  geom_hline(yintercept = 0, colour = "blue") +
  geom_point() + 
  theme_minimal()
```

Since the residuals are more clustered below it indicates we may have violated our assumption. In order to double check we'll perform a RESET. 

```{r}
resettest(reg1, power = 2)
resettest(reg4, power = 2)

```
The RESET test indicates that we can reject the null hypothesis at the 90% confidence level but not at the 95% confidence level. Normally we'd rework the model but since we already know that logs are likely needed for an ideal model and we know from the RESET test on reg1 that our model has improved so we'll keep reg4 as is. 


The final assumption is homoskedasticity, in otherwords that $Var(u|inc, narr86, nfarr86, pcnv, durat, race) = \sigma^2$. Our visualizations don't indicate any clear signs of homoskedasticity but to verify this we'll conduct a breusch-pagan test and a white test. The hypothesis test is as follows: $ H_{0}: Var(u|inc, narr86, nfarr86, pcnv, durat, race) = Var(u|X) = \sigma^2$ and the alternative where these values are not equal.
                
First we will use the BP test using the F statistic, then White test using F statistic, and both tests using LM ratio. Then, we will discuss the difference in the results they render. Keep in mind that a large F statistic or a large Lagrange multiplier statistic, (LM) indicate a rejection of the null hypothesis. 

```{r echo=FALSE}
# BP test (using F statistics) manually
#summary(lm(reg2A_df$.resid ~ log(inc86) + narr86 + nfarr86 + pcnv + durat + race, df))

bptest(reg4)
```

Using the BP test, we see that our p-value is relatively large (p-value = 0.197) meaning that our F-statistic is relatively small. Consequently, we fail to reject the null hypothesis. This indicates that heteroskedasticity isn't a concern. However, in order to be thorough we'll also run a white test which is a less rigouros test for homoskedasticity. 

```{r echo = FALSE}
# White test (using F statistic)
u_hat <- reg4$residuals
y_hat <- predict(reg4)

summary(lm(u_hat^2 ~ y_hat + I(y_hat^2)  ))
```
We have an F statistic of 1.211 and a p value of 0.3012 >.05. Therefore we fail to reject the null hypothesis indicating that despite our earlier concerns, heteroskedasticity is not an issue. Due to the results of the bp and white test won't make any standard error adjustments to our model. 

The regression as it stands now is 

```{r}
stargazer(reg4, type = "text")
```

$$ \widehat{log(Avgsen)} = 22.396 - 0.017(inc) - 4.089(narr86) + 1.217(narr86^2) - 28.877(pcnv) +  21.256(pcnv^2) + 0.184(durat) - 0.908(racehisp) - 3.127(racenon) $$
From the regression 4 output we can see our constant, pcnv and narr86 are all statistically significant. In order to determine if we should include the statistically insignificant variables we'll run a hypothesis test with the following null and alternative. 

$$H_{0}: inc86 = 0, durat = 0, racehisp = 0, racenon = 0$$
$$H_{1}: inc86 \neq 0, durat \neq 0, racehisp \neq 0, racenon \neq 0 $$

While $narr86^2$ is statistically insignificant we haven't included it in the our test given that $narr86$ is statistically significant and we already know that including the square is the correct form. 

```{r echo=FALSE}

Ho_joint <- c("inc86 = 0", "durat = 0", "racehisp = 0", "racenon = 0")
linearHypothesis(reg4, Ho_joint)


```

The results of the hyothesis test has a low F value of 1.3214 with a p value of 0.32657 which indicates that these values are not jointly significant so we'll remove those variables from our model, we can see the comparison with the removed variables here


```{r}
reg5 <- lm(avgsen ~  narr86 + narr86sq + pcnv + pcnvsq, df)
reg6 <- lm(avgsen ~  pcnv + pcnvsq, df)

stargazer(reg4, reg5, reg6, type = "text")
```
 
 Since narr86 becomes statstically insignificant in when the other variables are removed, we can attribute the statistical significance to mere noise in our data. Indicating our best regression is the following. 

$$ \widehat{ avgsen} = 20.197 -29.332(pcnv) + 22.040(pcnv)^2 $$
Since this equation is univariate, I'll also include a graphic 

```{r}
x <- 0:1
dat <- data.frame(x, y = 20.197 - 29.332*x + 22.040*x^2)
f <- function(x) 20.197 - 29.332*x + 22.040*x^2
ggplot(dat, aes(x,y)) + 
  ggtitle("Estminated Relationship from Regression Six") +
  xlab("Propotion of Prior Convictions") +
  ylab("Average Sentence Length") +
    geom_point() +
    stat_function(fun=f, colour="red")
```


## Model Interpretation and Implication 

Since regression 4 and regression 6 are statistically significant, we can still offer interpretive results of each variable with the caveat that the values are not statistically significant. Regression 4 predicts that for every \$100 increase in income theres a decrease in average prison sentence of 0.017 months. This is not only statistically insignificant but also practically insignificant as 0.017 months corresponds to less than a day. Since narr86 is a quadratic variable we need to solve the derivative of the quadratic is $-4.089 + 2.434narr86 = 0$ so $narr86 = 1.68$ and find the derivative which is positive. The solutions to our quadratic is 0 and `r 4.089/ 1.217`, indicating that narr86 and avgsen has a relationship that is increasing at a decreasing rate when $narr96 < 1.68$ but it has decreasing at increasing rate when $narr96 > 1.68$. These results indicat that the first 2 arrests increase average sentence length but arrests beyond the third decrease average sentence length which implies that individuals recieve lesser punishments for multiple arrests which is surprising given the expectations for harsher punishments for repeat offenders. However, since the result isn't statistically significant, we should let this result affect our judgement. 

Model four also provides an estimation for durat, for every one month increase in unemployment duration theres a 0.184 month increase in average sentence length. 0.184 corresponds to less than a week which is still of little practical significance as well as the statistical insignificance. Regression 4 also contains variables for measuring race. We have hispanic and non black, non hispanic individuals which are interpreted relative to black individuals. Hispanic individuals have an estimated average sentence 0.908 months less than black individuals and non black and non hispanic individuals have an estimated averagee sentence length 3.127 months less than black individuals. While these variables aren't statistically significant relationship, the results correspond to what we'd expect through both typical descrimination practices and crime trends by race. In other words, there are multiple explanations for why black individals have the longest average sentence length while non black non hispanic individuals have the lowest length. Next, we'll focus on our final regression with the statistically significant results. Like narr86 before, pcnv (proportion of prior convictions) is quadratic so we will need to solve the quadratic and calculate the derivative. Since pcnv is the only variable in this regression we'll include the constant when solving our regression. The derivative of this regression is $-29.332 + 44.08(pcnv) = 0$ so $ pcnv = 0.665 $. For $pcnv < 0.665$, pcnv and average sentence have a decreasing at an increasing rate but when $ pcnv > 0.665 $, pcnv and average sentence have a relationship that is increasing at an increasing rate. This implies that when conviction is less likely average sentence length decreases but when convictions are more probable, average sentence length is higher. While this is statistically significant, this fits as we'd expect that individuals who are arrested with higher liklihood of conviction are more likly to have convictions that lead to higher sentence length. 

In regards to our focus question, we cannot say that income has an affect on average sentencing for two reasons. First, the income coefficient was statistically insignificant. Second, our graph shows that income and average sentencing have a very small correlation. This may have been unexpected, but it is worth mentioning that our surveyed males were young adults who are 25-years-old and with low income and a prior arrest history. This makes their employment prospects grim and explains their low income. We know that if we include older males of different ages and with different income levels and no criminal history, we can see that income would in fact have an impact on average sentencing. 

In addition, looking at other key questions examined in this paper, we could say that the prior arrest ratio and recent unemployment variables were statistically insignificant, both individually and jointly. Our joint hypothesis proved that income, prior arrest ratio, and recent employment variables to be statistically insignificant, therefore their betas are unreliable.  Consequently, we cannot say anything about whether recent unemployment and prior arrest ratio have an impact on average sentencing. Lastly, it was expected that an individual with prior arrest would have a higher average sentence. This coefficient is statistically significant. Conversely, we did not expect an individual with a felony conviction to have a lower average sentence. This coefficient is statistically significant at the 1% level. However, our explanation is that people who are convicted of a felony crime tend to put up a legal fight and, as a result, it leads them to getting a smaller average sentence.

Additionally, we ended up dropping income, unemployment status, and the arrest ratio variables from our model. This helped render a higher adjusted R squared and improved the overall relationship between our explanatory variables and the dependent variable. We kept the race, prior arrest, and felony convictions due to their statistical significance. What is interesting is the race question. It turns out that blacks fared worse than Hispanics and other races. Our regression model rendered a statistically significant coefficient that ties blacks’ disadvantage in average sentencing. In contrast, Hispanics tended to fare better than blacks. However, other races fared better than both of them.

Finally, our econometric examination throughout the paper imparts some lessons our policy makers and researchers could glean to improve criminal justice reform and policy making. We can say that blacks are disadvantaged more than Hispanics and other races. Given this point, they must use this finding to propose and implement better criminal justice policies, and help close the gap in discrimination toward blacks. For our nation to envision its prosperous future and for us to help make it “a more perfect union” as the founders admonished, it is critical that they address discrimination against blacks in the criminal justice system.

